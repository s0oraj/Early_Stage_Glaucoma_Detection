{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4983 images belonging to 2 classes.\n",
      "{'Glaucoma': 0, 'Healthy': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-28 23:01:58.466831: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " new_flatten (Flatten)       (None, 4096)              0         \n",
      "                                                                 \n",
      " new_fc (Dense)              (None, 128)               524416    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,785,218\n",
      "Trainable params: 524,674\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 200704 into shape (1,224,224,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m     df\u001b[39m.\u001b[39mto_pickle(\u001b[39m\"\u001b[39m\u001b[39mG1020_VGG16.pickle\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 74\u001b[0m     main();\n",
      "Cell \u001b[0;32mIn[2], line 70\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m vgg_model_a \u001b[39m=\u001b[39m getVGG16Model(lastFourTrainable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m);\n\u001b[1;32m     69\u001b[0m feature_model_vgg_a \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39mvgg_model_a\u001b[39m.\u001b[39minput , outputs\u001b[39m=\u001b[39mvgg_model_a\u001b[39m.\u001b[39mget_layer(\u001b[39m'\u001b[39m\u001b[39mnew_fc\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39moutput)\n\u001b[0;32m---> 70\u001b[0m df \u001b[39m=\u001b[39m getFeatureDataFrame(feature_model_vgg_a)\n\u001b[1;32m     71\u001b[0m df\u001b[39m.\u001b[39mto_pickle(\u001b[39m\"\u001b[39m\u001b[39mG1020_VGG16.pickle\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 63\u001b[0m, in \u001b[0;36mgetFeatureDataFrame\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     61\u001b[0m files \u001b[39m=\u001b[39m train_files ; \n\u001b[1;32m     62\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m files \n\u001b[0;32m---> 63\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m row:getFeatureVector(model,row[\u001b[39m'\u001b[39;49m\u001b[39mfile\u001b[39;49m\u001b[39m'\u001b[39;49m]),axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     64\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:9565\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9554\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9556\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9557\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9558\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9563\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9564\u001b[0m )\n\u001b[0;32m-> 9565\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:746\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    744\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 746\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 873\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    875\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:889\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    887\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    888\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    890\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    891\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    892\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    893\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 63\u001b[0m, in \u001b[0;36mgetFeatureDataFrame.<locals>.<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     61\u001b[0m files \u001b[39m=\u001b[39m train_files ; \n\u001b[1;32m     62\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m files \n\u001b[0;32m---> 63\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row:getFeatureVector(model,row[\u001b[39m'\u001b[39;49m\u001b[39mfile\u001b[39;49m\u001b[39m'\u001b[39;49m]),axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "Cell \u001b[0;32mIn[2], line 55\u001b[0m, in \u001b[0;36mgetFeatureVector\u001b[0;34m(model, img_path)\u001b[0m\n\u001b[1;32m     53\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img,(\u001b[39m224\u001b[39m,\u001b[39m224\u001b[39m))\n\u001b[1;32m     54\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img,cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGBA)\n\u001b[0;32m---> 55\u001b[0m feature_vector \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(img\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m,\u001b[39m224\u001b[39;49m,\u001b[39m224\u001b[39;49m,\u001b[39m3\u001b[39;49m))\n\u001b[1;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m feature_vector\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 200704 into shape (1,224,224,3)"
     ]
    }
   ],
   "source": [
    "import numpy as np ;\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Reshape,Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "import itertools \n",
    "import cv2\n",
    "import pandas as pd ;\n",
    "import matplotlib.pyplot as plt ;\n",
    "\n",
    "train_directory  = \"G1020\"\n",
    "\n",
    "#Constants \n",
    "img_rows = 224 \n",
    "img_cols = 224 \n",
    "inputshape = (img_rows,img_cols,3)\n",
    "epochs = 2\n",
    "batch_size = 5\n",
    "num_of_classes = 2 \n",
    "num_of_train_samples = 4983\n",
    "\n",
    "train_generator = ImageDataGenerator().flow_from_directory(directory=train_directory , \n",
    "                                                        class_mode='categorical',\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        target_size=(img_rows,img_cols),\n",
    "                                                        color_mode=\"rgb\",\n",
    "                                                        shuffle=False);\n",
    "print(train_generator.class_indices)\n",
    "def getVGG16Model(lastFourTrainable = False):\n",
    "    vgg_model = VGG16(weights='imagenet',input_shape=inputshape , include_top=True)\n",
    "    for layer in vgg_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "    output = vgg_model.get_layer('fc2').output\n",
    "    output=Flatten(name='new_flatten' )(output) \n",
    "    output = Dense(units=128, activation='relu',name='new_fc')(output)\n",
    "    output = Dense(units=2,activation='softmax')(output)\n",
    "    vgg_model = Model(vgg_model.input , output)\n",
    "\n",
    "    if lastFourTrainable == True:\n",
    "        vgg_model.get_layer('block5_conv3').trainable = True\n",
    "        vgg_model.get_layer('fc1').trainable = True\n",
    "        vgg_model.get_layer('fc2').trainable = True\n",
    "        vgg_model.get_layer('new_fc').trainable = True\n",
    "\n",
    "    vgg_model.compile(optimizer='adam' , loss='catagorical_crossentropy',metrics=['accuracy'])\n",
    "    vgg_model.summary()\n",
    "\n",
    "    return vgg_model;\n",
    "\n",
    "def getFeatureVector(model ,img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img,(224,224))\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    feature_vector = model.predict(img.reshape(1,224,224,3))\n",
    "    return feature_vector\n",
    "\n",
    "def getFeatureDataFrame(model):\n",
    "    df= pd.DataFrame(columns=['file','features'])\n",
    "    train_files = train_generator.filepaths ; \n",
    "    files = train_files ; \n",
    "    df['file'] = files \n",
    "    df['features'] = df.apply(lambda row:getFeatureVector(model,row['file']),axis=1)\n",
    "    return df \n",
    "\n",
    "    \n",
    "def main():\n",
    "    vgg_model_a = getVGG16Model(lastFourTrainable=False);\n",
    "    feature_model_vgg_a = Model(inputs=vgg_model_a.input , outputs=vgg_model_a.get_layer('new_fc').output)\n",
    "    df = getFeatureDataFrame(feature_model_vgg_a)\n",
    "    df.to_pickle(\"G1020_VGG16.pickle\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
